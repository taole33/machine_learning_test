{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0505yolo_recognize.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1KlqQFEeJcPBq0Ly8YxBLRAq5M9WjvL03","authorship_tag":"ABX9TyN3zI8SKjgzmbTiOmicV4rY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y5FD725CZyAh","executionInfo":{"status":"ok","timestamp":1612348494668,"user_tz":-540,"elapsed":3091,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"82fa1c53-b007-4746-a542-58e6ba8e2479"},"source":["!git clone https://github.com/pjreddie/darknet"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'darknet'...\n","remote: Enumerating objects: 5931, done.\u001b[K\n","remote: Total 5931 (delta 0), reused 0 (delta 0), pack-reused 5931\u001b[K\n","Receiving objects: 100% (5931/5931), 6.34 MiB | 24.15 MiB/s, done.\n","Resolving deltas: 100% (3925/3925), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Nfk1jQHrqCh","executionInfo":{"status":"ok","timestamp":1612513184847,"user_tz":-540,"elapsed":1224,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"316c0c55-e886-45e0-fec2-4d9adc6f142f"},"source":["!git clone https://github.com/sleepless-se/keras-yolo3.git keras-yolo3-sample"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'keras-yolo3-sample'...\n","remote: Enumerating objects: 211, done.\u001b[K\n","remote: Total 211 (delta 0), reused 0 (delta 0), pack-reused 211\u001b[K\n","Receiving objects: 100% (211/211), 161.77 KiB | 4.15 MiB/s, done.\n","Resolving deltas: 100% (105/105), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pULytr8DwagC","executionInfo":{"status":"ok","timestamp":1612513194235,"user_tz":-540,"elapsed":671,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"256e9d74-ee26-4011-a946-5fab33f19b7f"},"source":["cd keras-yolo3-sample"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/keras-yolo3-sample\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"BFx4XdpGweso","executionInfo":{"status":"ok","timestamp":1612513279146,"user_tz":-540,"elapsed":82849,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"4b02963b-21f2-477f-fd40-ba32532d0221"},"source":["!pip install -r requirements.txt"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting absl-py==0.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\n","\r\u001b[K     |███▎                            | 10kB 19.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 20kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 40kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 61kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 92kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 4.2MB/s \n","\u001b[?25hCollecting astor==0.8.0\n","  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n","Collecting bleach==1.5.0\n","  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n","Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.10.0)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Collecting grpcio==1.21.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/83/18f374294bf34128a448ee2fae37651f943b0b5fa473b5b3aff262c15bf8/grpcio-1.21.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.2MB 22.2MB/s \n","\u001b[?25hCollecting h5py==2.9.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n","\u001b[K     |████████████████████████████████| 2.8MB 41.1MB/s \n","\u001b[?25hCollecting html5lib==0.9999999\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n","\u001b[K     |████████████████████████████████| 890kB 53.4MB/s \n","\u001b[?25hCollecting Keras==2.1.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/65/e4aff762b8696ec0626a6654b1e73b396fcc8b7cc6b98d78a1bc53b85b48/Keras-2.1.5-py2.py3-none-any.whl (334kB)\n","\u001b[K     |████████████████████████████████| 337kB 43.1MB/s \n","\u001b[?25hCollecting kiwisolver==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/a1/5742b56282449b1c0968197f63eae486eca2c35dcd334bab75ad524e0de1/kiwisolver-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (90kB)\n","\u001b[K     |████████████████████████████████| 92kB 12.1MB/s \n","\u001b[?25hCollecting Markdown==3.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n","\u001b[K     |████████████████████████████████| 92kB 12.1MB/s \n","\u001b[?25hCollecting matplotlib==3.0.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/69/f5e05f578585ed9935247be3788b374f90701296a70c8871bcd6d21edb00/matplotlib-3.0.3-cp36-cp36m-manylinux1_x86_64.whl (13.0MB)\n","\u001b[K     |████████████████████████████████| 13.0MB 253kB/s \n","\u001b[?25hCollecting numpy==1.16.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n","\u001b[K     |████████████████████████████████| 17.3MB 214kB/s \n","\u001b[?25hCollecting Pillow==6.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/c2/f84b1e57416755e967236468dcfb0fad7fd911f707185efc4ba8834a1a94/Pillow-6.0.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n","\u001b[K     |████████████████████████████████| 2.0MB 47.8MB/s \n","\u001b[?25hCollecting protobuf==3.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/fb/29de8d08967f0cce1bb10b39846d836b0f3bf6776ddc36aed7c73498ca7e/protobuf-3.8.0-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 48.2MB/s \n","\u001b[?25hCollecting pyparsing==2.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d9/3ec19e966301a6e25769976999bd7bbe552016f0d32b577dc9d63d2e0c49/pyparsing-2.4.0-py2.py3-none-any.whl (62kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.8MB/s \n","\u001b[?25hCollecting python-dateutil==2.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n","\u001b[K     |████████████████████████████████| 235kB 52.6MB/s \n","\u001b[?25hCollecting PyYAML==5.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n","\u001b[K     |████████████████████████████████| 276kB 29.1MB/s \n","\u001b[?25hCollecting scipy==1.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/4c/5f81e7264b0a7a8bd570810f48cd346ba36faedbd2ba255c873ad556de76/scipy-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n","\u001b[K     |████████████████████████████████| 25.2MB 138kB/s \n","\u001b[?25hCollecting six==1.12.0\n","  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n","Collecting tensorboard==1.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/67/a8c91665987d359211dcdca5c8b2a7c1e0876eb0702a4383c1e4ff76228d/tensorboard-1.6.0-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 47.0MB/s \n","\u001b[?25hCollecting tensorflow==1.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/0f/fbd8bb92459c75db93040f80702ebe4ba83a52cdb6ad930654c31dc0b711/tensorflow-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (45.8MB)\n","\u001b[K     |████████████████████████████████| 45.9MB 68kB/s \n","\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 23)) (1.1.0)\n","Collecting Werkzeug==0.15.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/57/92a497e38161ce40606c27a86759c6b92dd34fcdb33f64171ec559257c02/Werkzeug-0.15.4-py2.py3-none-any.whl (327kB)\n","\u001b[K     |████████████████████████████████| 327kB 47.8MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver==1.1.0->-r requirements.txt (line 10)) (53.0.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.6.0->-r requirements.txt (line 21)) (0.36.2)\n","Building wheels for collected packages: absl-py, gast, html5lib, PyYAML\n","  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for absl-py: filename=absl_py-0.7.1-cp36-none-any.whl size=117848 sha256=700ff18ca9c0bb30d9d01ed2e69db193cb319181c026b6b5d740594a3ac6645a\n","  Stored in directory: /root/.cache/pip/wheels/ee/98/38/46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=27cd30a90a802cfdd3dd74f42098580bc8a9112e5623a8c5bc20383f4a9973c2\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107222 sha256=6bbf29b332604fe7df7b2dcfc823807849a3c7f642bda45b986ec40702925c0a\n","  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n","  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyYAML: filename=PyYAML-5.1.1-cp36-cp36m-linux_x86_64.whl size=44101 sha256=cafa0b99a4e226be3b68029d7248f95b4e2680019cb7f4a8021fdeb6b7f76fcb\n","  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n","Successfully built absl-py gast html5lib PyYAML\n","\u001b[31mERROR: umap-learn 0.5.0 has requirement numpy>=1.17, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-metadata 0.27.0 has requirement absl-py<0.11,>=0.9, but you'll have absl-py 0.7.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.0.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: nbclient 0.5.1 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.0.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement astor~=0.8.1, but you'll have astor 0.8.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: six, absl-py, astor, html5lib, bleach, gast, grpcio, numpy, h5py, PyYAML, scipy, Keras, kiwisolver, Markdown, python-dateutil, pyparsing, matplotlib, Pillow, protobuf, Werkzeug, tensorboard, tensorflow\n","  Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Found existing installation: absl-py 0.10.0\n","    Uninstalling absl-py-0.10.0:\n","      Successfully uninstalled absl-py-0.10.0\n","  Found existing installation: astor 0.8.1\n","    Uninstalling astor-0.8.1:\n","      Successfully uninstalled astor-0.8.1\n","  Found existing installation: html5lib 1.0.1\n","    Uninstalling html5lib-1.0.1:\n","      Successfully uninstalled html5lib-1.0.1\n","  Found existing installation: bleach 3.3.0\n","    Uninstalling bleach-3.3.0:\n","      Successfully uninstalled bleach-3.3.0\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: grpcio 1.32.0\n","    Uninstalling grpcio-1.32.0:\n","      Successfully uninstalled grpcio-1.32.0\n","  Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Found existing installation: h5py 2.10.0\n","    Uninstalling h5py-2.10.0:\n","      Successfully uninstalled h5py-2.10.0\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","  Found existing installation: Keras 2.4.3\n","    Uninstalling Keras-2.4.3:\n","      Successfully uninstalled Keras-2.4.3\n","  Found existing installation: kiwisolver 1.3.1\n","    Uninstalling kiwisolver-1.3.1:\n","      Successfully uninstalled kiwisolver-1.3.1\n","  Found existing installation: Markdown 3.3.3\n","    Uninstalling Markdown-3.3.3:\n","      Successfully uninstalled Markdown-3.3.3\n","  Found existing installation: python-dateutil 2.8.1\n","    Uninstalling python-dateutil-2.8.1:\n","      Successfully uninstalled python-dateutil-2.8.1\n","  Found existing installation: pyparsing 2.4.7\n","    Uninstalling pyparsing-2.4.7:\n","      Successfully uninstalled pyparsing-2.4.7\n","  Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","  Found existing installation: Pillow 7.0.0\n","    Uninstalling Pillow-7.0.0:\n","      Successfully uninstalled Pillow-7.0.0\n","  Found existing installation: protobuf 3.12.4\n","    Uninstalling protobuf-3.12.4:\n","      Successfully uninstalled protobuf-3.12.4\n","  Found existing installation: Werkzeug 1.0.1\n","    Uninstalling Werkzeug-1.0.1:\n","      Successfully uninstalled Werkzeug-1.0.1\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","  Found existing installation: tensorflow 2.4.1\n","    Uninstalling tensorflow-2.4.1:\n","      Successfully uninstalled tensorflow-2.4.1\n","Successfully installed Keras-2.1.5 Markdown-3.1.1 Pillow-6.0.0 PyYAML-5.1.1 Werkzeug-0.15.4 absl-py-0.7.1 astor-0.8.0 bleach-1.5.0 gast-0.2.2 grpcio-1.21.1 h5py-2.9.0 html5lib-0.9999999 kiwisolver-1.1.0 matplotlib-3.0.3 numpy-1.16.4 protobuf-3.8.0 pyparsing-2.4.0 python-dateutil-2.8.0 scipy-1.3.0 six-1.12.0 tensorboard-1.6.0 tensorflow-1.6.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL","astor","dateutil","google","kiwisolver","matplotlib","mpl_toolkits","numpy","pyparsing","six"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":354},"id":"7IPnjS401kt9","executionInfo":{"status":"error","timestamp":1612421995770,"user_tz":-540,"elapsed":49976,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"3ef2d828-87e8-4fe6-a514-b42c84034542"},"source":["from google.colab import files\r\n","files.upload()"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-13447f24-f79e-4ea5-8917-393f23258beb\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-13447f24-f79e-4ea5-8917-393f23258beb\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-5c2e8a8d365b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ASjGaIz2v4d","executionInfo":{"status":"ok","timestamp":1612513332931,"user_tz":-540,"elapsed":763,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"3b293aaa-6e40-4346-f208-11c6cab8e365"},"source":["cd /content/keras-yolo3-sample/"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/keras-yolo3-sample\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5wkPcUeRr3B8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612514125653,"user_tz":-540,"elapsed":732,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"ab2bd2cb-78b5-4d99-ccbd-7bb609085084"},"source":["import os\r\n","import pandas\r\n","main_dir = 'VOCDevkit/VOC2007/ImageSets/Main/'\r\n","os.chdir(main_dir)\r\n","pwd = os.getcwd()\r\n","print(pwd)\r\n","\r\n","\r\n","def make_train_files():\r\n","    suffixs = ['_train','_val','_test']\r\n","\r\n","    for suffix in suffixs:\r\n","        print('suffix',suffix)\r\n","        new_file = open('{}.txt'.format(suffix.replace('_','')),'w')\r\n","        text = \"\"\r\n","        for file in os.listdir():\r\n","            if file.find(suffix) == -1:continue\r\n","            with open(file) as f:\r\n","                if text == \"\":text = f.read()\r\n","                text =text +'\\n'+ f.read()\r\n","        new_file.write(text)\r\n","\r\n","def split_val_test(rate:float):\r\n","    val = pandas.read_csv('val.txt')\r\n","    val = val.sample(frac=1)\r\n","    print('len',len(val))\r\n","    split = int(len(val) * rate)\r\n","    test = val.values\r\n","    val[:split].to_csv('val.txt',index=False)\r\n","    val[split:].to_csv('test.txt',index=False)\r\n","    print('val.txt',split)\r\n","    print('test.txt',len(val) - split)\r\n","\r\n","if __name__ == '__main__':\r\n","    val_rate = 0.33\r\n","    make_train_files()\r\n","    split_val_test(val_rate)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/content/keras-yolo3-sample/VOCDevkit/VOC2007/ImageSets/Main\n","suffix _train\n","suffix _val\n","suffix _test\n","len 19\n","val.txt 6\n","test.txt 13\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DD5ExwRGywY_","executionInfo":{"status":"ok","timestamp":1612514205568,"user_tz":-540,"elapsed":1047,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"eea226b6-33cb-4739-bbfc-019e7e4b1379"},"source":["cd .."],"execution_count":21,"outputs":[{"output_type":"stream","text":["/content/keras-yolo3-sample\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vyg3msaEdNPv","executionInfo":{"status":"ok","timestamp":1612514209049,"user_tz":-540,"elapsed":676,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}}},"source":["import xml.etree.ElementTree as ET\r\n","from os import getcwd\r\n","import sys,os\r\n","sets=[('2007', 'train'), ('2007', 'val'), ('2007', 'test')]\r\n","\r\n","classes = [\"solar_panel\"]\r\n","\r\n","if len(sys.argv) > 1:\r\n","    classes = sys.argv[1:]\r\n","\r\n","with open('model_data/voc_classes.txt','w') as f:\r\n","    f.write('\\n'.join(classes))\r\n","\r\n","\r\n","def convert_annotation(year, image_id, list_file):\r\n","    in_file = open('VOCDevkit/VOC%s/Annotations/%s.xml'%(year, image_id.replace(\".jpg\",\"\")))\r\n","    tree=ET.parse(in_file)\r\n","    root = tree.getroot()\r\n","\r\n","    for obj in root.iter('object'):\r\n","        difficult = obj.find('difficult').text\r\n","        cls = obj.find('name').text\r\n","        if cls not in classes or int(difficult)==1:\r\n","            continue\r\n","        cls_id = classes.index(cls)\r\n","        xmlbox = obj.find('bndbox')\r\n","        b = (int(float(xmlbox.find('xmin').text)),\r\n","             int(float(xmlbox.find('ymin').text)),\r\n","             int(float(xmlbox.find('xmax').text)),\r\n","             int(float(xmlbox.find('ymax').text)))\r\n","        list_file.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))\r\n","\r\n","wd = getcwd()\r\n","\r\n","for year, image_set in sets:\r\n","    image_ids = open('VOCDevkit/VOC%s/ImageSets/Main/%s.txt'%(year, image_set)).read().strip().split()\r\n","    list_file = open('model_data/%s_%s.txt'%(year, image_set), 'w')\r\n","    for image_id in image_ids:\r\n","        if image_id == '1': continue\r\n","        if image_id == '-1': continue\r\n","        image_file_path = '%s/VOCDevkit/VOC%s/JPEGImages/%s'%(wd, year, image_id)\r\n","        list_file.write(image_file_path)\r\n","        convert_annotation(year, image_id, list_file)\r\n","        list_file.write('\\n')\r\n","    list_file.close()"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iz77lwiAfJYo","executionInfo":{"status":"ok","timestamp":1612383417510,"user_tz":-540,"elapsed":1540,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"3f93e068-25d0-4ba6-b5b6-fcd4ab4745a9"},"source":["print(os.getcwd())"],"execution_count":47,"outputs":[{"output_type":"stream","text":["/content/keras-yolo3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gWJt30Wfj_C1","executionInfo":{"status":"ok","timestamp":1612383792382,"user_tz":-540,"elapsed":4005,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"55bf812f-f935-45a5-d647-519679fc05fd"},"source":["!pip install keras"],"execution_count":56,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.19.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ccmK3QZuzI2w","executionInfo":{"status":"ok","timestamp":1612513960059,"user_tz":-540,"elapsed":543651,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"16065dc4-e0e7-45ea-e525-eadba1a70e40"},"source":["!wget https://pjreddie.com/media/files/yolov3.weights"],"execution_count":13,"outputs":[{"output_type":"stream","text":["--2021-02-05 08:23:36--  https://pjreddie.com/media/files/yolov3.weights\n","Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n","Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 248007048 (237M) [application/octet-stream]\n","Saving to: ‘yolov3.weights’\n","\n","yolov3.weights      100%[===================>] 236.52M   377KB/s    in 9m 3s   \n","\n","2021-02-05 08:32:39 (446 KB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6LGVc5mzMGX","executionInfo":{"status":"ok","timestamp":1612514030238,"user_tz":-540,"elapsed":66599,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"3e2c3fbc-94d5-4cb7-ed4d-bc4b4a108b24"},"source":["!python convert.py -w yolov3.cfg yolov3.weights model_data/yolo_weights.h5\r\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","Loading weights.\n","Weights Header:  0 2 0 [32013312]\n","Parsing Darknet config.\n","Creating Keras model.\n","Parsing section net_0\n","Parsing section convolutional_0\n","conv2d bn leaky (3, 3, 3, 32)\n","2021-02-05 08:32:45.177463: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","Parsing section convolutional_1\n","conv2d bn leaky (3, 3, 32, 64)\n","Parsing section convolutional_2\n","conv2d bn leaky (1, 1, 64, 32)\n","Parsing section convolutional_3\n","conv2d bn leaky (3, 3, 32, 64)\n","Parsing section shortcut_0\n","Parsing section convolutional_4\n","conv2d bn leaky (3, 3, 64, 128)\n","Parsing section convolutional_5\n","conv2d bn leaky (1, 1, 128, 64)\n","Parsing section convolutional_6\n","conv2d bn leaky (3, 3, 64, 128)\n","Parsing section shortcut_1\n","Parsing section convolutional_7\n","conv2d bn leaky (1, 1, 128, 64)\n","Parsing section convolutional_8\n","conv2d bn leaky (3, 3, 64, 128)\n","Parsing section shortcut_2\n","Parsing section convolutional_9\n","conv2d bn leaky (3, 3, 128, 256)\n","Parsing section convolutional_10\n","conv2d bn leaky (1, 1, 256, 128)\n","Parsing section convolutional_11\n","conv2d bn leaky (3, 3, 128, 256)\n","Parsing section shortcut_3\n","Parsing section convolutional_12\n","conv2d bn leaky (1, 1, 256, 128)\n","Parsing section convolutional_13\n","conv2d bn leaky (3, 3, 128, 256)\n","Parsing section shortcut_4\n","Parsing section convolutional_14\n","conv2d bn leaky (1, 1, 256, 128)\n","Parsing section convolutional_15\n","conv2d bn leaky (3, 3, 128, 256)\n","Parsing section shortcut_5\n","Parsing section convolutional_16\n","conv2d bn leaky (1, 1, 256, 128)\n","Parsing section convolutional_17\n","conv2d bn leaky (3, 3, 128, 256)\n","Parsing section shortcut_6\n","Parsing section convolutional_18\n","conv2d bn leaky (1, 1, 256, 128)\n","Parsing section convolutional_19\n","conv2d bn leaky (3, 3, 128, 256)\n","Parsing section shortcut_7\n","Parsing section convolutional_20\n","conv2d bn leaky (1, 1, 256, 128)\n","Parsing section convolutional_21\n","conv2d bn leaky (3, 3, 128, 256)\n","Parsing section shortcut_8\n","Parsing section convolutional_22\n","conv2d bn leaky (1, 1, 256, 128)\n","Parsing section convolutional_23\n","conv2d bn leaky (3, 3, 128, 256)\n","Parsing section shortcut_9\n","Parsing section convolutional_24\n","conv2d bn leaky (1, 1, 256, 128)\n","Parsing section convolutional_25\n","conv2d bn leaky (3, 3, 128, 256)\n","Parsing section shortcut_10\n","Parsing section convolutional_26\n","conv2d bn leaky (3, 3, 256, 512)\n","Parsing section convolutional_27\n","conv2d bn leaky (1, 1, 512, 256)\n","Parsing section convolutional_28\n","conv2d bn leaky (3, 3, 256, 512)\n","Parsing section shortcut_11\n","Parsing section convolutional_29\n","conv2d bn leaky (1, 1, 512, 256)\n","Parsing section convolutional_30\n","conv2d bn leaky (3, 3, 256, 512)\n","Parsing section shortcut_12\n","Parsing section convolutional_31\n","conv2d bn leaky (1, 1, 512, 256)\n","Parsing section convolutional_32\n","conv2d bn leaky (3, 3, 256, 512)\n","Parsing section shortcut_13\n","Parsing section convolutional_33\n","conv2d bn leaky (1, 1, 512, 256)\n","Parsing section convolutional_34\n","conv2d bn leaky (3, 3, 256, 512)\n","Parsing section shortcut_14\n","Parsing section convolutional_35\n","conv2d bn leaky (1, 1, 512, 256)\n","Parsing section convolutional_36\n","conv2d bn leaky (3, 3, 256, 512)\n","Parsing section shortcut_15\n","Parsing section convolutional_37\n","conv2d bn leaky (1, 1, 512, 256)\n","Parsing section convolutional_38\n","conv2d bn leaky (3, 3, 256, 512)\n","Parsing section shortcut_16\n","Parsing section convolutional_39\n","conv2d bn leaky (1, 1, 512, 256)\n","Parsing section convolutional_40\n","conv2d bn leaky (3, 3, 256, 512)\n","Parsing section shortcut_17\n","Parsing section convolutional_41\n","conv2d bn leaky (1, 1, 512, 256)\n","Parsing section convolutional_42\n","conv2d bn leaky (3, 3, 256, 512)\n","Parsing section shortcut_18\n","Parsing section convolutional_43\n","conv2d bn leaky (3, 3, 512, 1024)\n","Parsing section convolutional_44\n","conv2d bn leaky (1, 1, 1024, 512)\n","Parsing section convolutional_45\n","conv2d bn leaky (3, 3, 512, 1024)\n","Parsing section shortcut_19\n","Parsing section convolutional_46\n","conv2d bn leaky (1, 1, 1024, 512)\n","Parsing section convolutional_47\n","conv2d bn leaky (3, 3, 512, 1024)\n","Parsing section shortcut_20\n","Parsing section convolutional_48\n","conv2d bn leaky (1, 1, 1024, 512)\n","Parsing section convolutional_49\n","conv2d bn leaky (3, 3, 512, 1024)\n","Parsing section shortcut_21\n","Parsing section convolutional_50\n","conv2d bn leaky (1, 1, 1024, 512)\n","Parsing section convolutional_51\n","conv2d bn leaky (3, 3, 512, 1024)\n","Parsing section shortcut_22\n","Parsing section convolutional_52\n","conv2d bn leaky (1, 1, 1024, 512)\n","Parsing section convolutional_53\n","conv2d bn leaky (3, 3, 512, 1024)\n","Parsing section convolutional_54\n","conv2d bn leaky (1, 1, 1024, 512)\n","Parsing section convolutional_55\n","conv2d bn leaky (3, 3, 512, 1024)\n","Parsing section convolutional_56\n","conv2d bn leaky (1, 1, 1024, 512)\n","Parsing section convolutional_57\n","conv2d bn leaky (3, 3, 512, 1024)\n","Parsing section convolutional_58\n","conv2d    linear (1, 1, 1024, 255)\n","Parsing section yolo_0\n","Parsing section route_0\n","Parsing section convolutional_59\n","conv2d bn leaky (1, 1, 512, 256)\n","Parsing section upsample_0\n","Parsing section route_1\n","Concatenating route layers: [<tf.Tensor 'up_sampling2d_1/ResizeNearestNeighbor:0' shape=(?, ?, ?, 256) dtype=float32>, <tf.Tensor 'add_19/add:0' shape=(?, ?, ?, 512) dtype=float32>]\n","Parsing section convolutional_60\n","conv2d bn leaky (1, 1, 768, 256)\n","Parsing section convolutional_61\n","conv2d bn leaky (3, 3, 256, 512)\n","Parsing section convolutional_62\n","conv2d bn leaky (1, 1, 512, 256)\n","Parsing section convolutional_63\n","conv2d bn leaky (3, 3, 256, 512)\n","Parsing section convolutional_64\n","conv2d bn leaky (1, 1, 512, 256)\n","Parsing section convolutional_65\n","conv2d bn leaky (3, 3, 256, 512)\n","Parsing section convolutional_66\n","conv2d    linear (1, 1, 512, 255)\n","Parsing section yolo_1\n","Parsing section route_2\n","Parsing section convolutional_67\n","conv2d bn leaky (1, 1, 256, 128)\n","Parsing section upsample_1\n","Parsing section route_3\n","Concatenating route layers: [<tf.Tensor 'up_sampling2d_2/ResizeNearestNeighbor:0' shape=(?, ?, ?, 128) dtype=float32>, <tf.Tensor 'add_11/add:0' shape=(?, ?, ?, 256) dtype=float32>]\n","Parsing section convolutional_68\n","conv2d bn leaky (1, 1, 384, 128)\n","Parsing section convolutional_69\n","conv2d bn leaky (3, 3, 128, 256)\n","Parsing section convolutional_70\n","conv2d bn leaky (1, 1, 256, 128)\n","Parsing section convolutional_71\n","conv2d bn leaky (3, 3, 128, 256)\n","Parsing section convolutional_72\n","conv2d bn leaky (1, 1, 256, 128)\n","Parsing section convolutional_73\n","conv2d bn leaky (3, 3, 128, 256)\n","Parsing section convolutional_74\n","conv2d    linear (1, 1, 256, 255)\n","Parsing section yolo_2\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None, None, 3 0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, None, None, 3 128         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","zero_padding2d_1 (ZeroPadding2D (None, None, None, 3 0           leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, None, None, 6 18432       zero_padding2d_1[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, None, None, 6 256         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, None, None, 3 2048        leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, None, None, 3 128         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, None, None, 6 18432       leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, None, None, 6 256         conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, None, None, 6 0           leaky_re_lu_2[0][0]              \n","                                                                 leaky_re_lu_4[0][0]              \n","__________________________________________________________________________________________________\n","zero_padding2d_2 (ZeroPadding2D (None, None, None, 6 0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, None, None, 1 73728       zero_padding2d_2[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, None, None, 1 512         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, None, None, 6 8192        leaky_re_lu_5[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, None, None, 6 256         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_6[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, None, None, 1 512         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, None, None, 1 0           leaky_re_lu_5[0][0]              \n","                                                                 leaky_re_lu_7[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, None, None, 6 8192        add_2[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, None, None, 6 256         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_8 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_8[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, None, None, 1 512         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_9 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, None, None, 1 0           add_2[0][0]                      \n","                                                                 leaky_re_lu_9[0][0]              \n","__________________________________________________________________________________________________\n","zero_padding2d_3 (ZeroPadding2D (None, None, None, 1 0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, None, None, 2 294912      zero_padding2d_3[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, None, None, 2 1024        conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_10 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_10[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, None, None, 1 512         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_11 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_11[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, None, None, 2 1024        conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_12 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, None, None, 2 0           leaky_re_lu_10[0][0]             \n","                                                                 leaky_re_lu_12[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, None, None, 1 32768       add_4[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, None, None, 1 512         conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_13 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_13[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, None, None, 2 1024        conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_14 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, None, None, 2 0           add_4[0][0]                      \n","                                                                 leaky_re_lu_14[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, None, None, 1 32768       add_5[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, None, None, 1 512         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_15 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_15[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, None, None, 2 1024        conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_16 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, None, None, 2 0           add_5[0][0]                      \n","                                                                 leaky_re_lu_16[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, None, None, 1 32768       add_6[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, None, None, 1 512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_17 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_17[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, None, None, 2 1024        conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_18 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, None, None, 2 0           add_6[0][0]                      \n","                                                                 leaky_re_lu_18[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, None, None, 1 32768       add_7[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, None, None, 1 512         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_19 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_19[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, None, None, 2 1024        conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_20 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, None, None, 2 0           add_7[0][0]                      \n","                                                                 leaky_re_lu_20[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, None, None, 1 32768       add_8[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, None, None, 1 512         conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_21 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_21[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, None, None, 2 1024        conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_22 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, None, None, 2 0           add_8[0][0]                      \n","                                                                 leaky_re_lu_22[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, None, None, 1 32768       add_9[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, None, None, 1 512         conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_23 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_23[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, None, None, 2 1024        conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_24 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, None, None, 2 0           add_9[0][0]                      \n","                                                                 leaky_re_lu_24[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, None, None, 1 32768       add_10[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, None, None, 1 512         conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_25 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_25[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, None, None, 2 1024        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_26 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, None, None, 2 0           add_10[0][0]                     \n","                                                                 leaky_re_lu_26[0][0]             \n","__________________________________________________________________________________________________\n","zero_padding2d_4 (ZeroPadding2D (None, None, None, 2 0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, None, None, 5 1179648     zero_padding2d_4[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, None, None, 5 2048        conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_27 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_27[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, None, None, 2 1024        conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_28 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_28[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, None, None, 5 2048        conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_29 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, None, None, 5 0           leaky_re_lu_27[0][0]             \n","                                                                 leaky_re_lu_29[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, None, None, 2 131072      add_12[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, None, None, 2 1024        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_30 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_30[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, None, None, 5 2048        conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_31 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, None, None, 5 0           add_12[0][0]                     \n","                                                                 leaky_re_lu_31[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, None, None, 2 131072      add_13[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, None, None, 2 1024        conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_32 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_32[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, None, None, 5 2048        conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_33 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, None, None, 5 0           add_13[0][0]                     \n","                                                                 leaky_re_lu_33[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, None, None, 2 131072      add_14[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, None, None, 2 1024        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_34 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_34[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, None, None, 5 2048        conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_35 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, None, None, 5 0           add_14[0][0]                     \n","                                                                 leaky_re_lu_35[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, None, None, 2 131072      add_15[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, None, None, 2 1024        conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_36 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_36[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, None, None, 5 2048        conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_37 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, None, None, 5 0           add_15[0][0]                     \n","                                                                 leaky_re_lu_37[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, None, None, 2 131072      add_16[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, None, None, 2 1024        conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_38 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_38[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, None, None, 5 2048        conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_39 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","add_17 (Add)                    (None, None, None, 5 0           add_16[0][0]                     \n","                                                                 leaky_re_lu_39[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, None, None, 2 131072      add_17[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, None, None, 2 1024        conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_40 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_40[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, None, None, 5 2048        conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_41 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","add_18 (Add)                    (None, None, None, 5 0           add_17[0][0]                     \n","                                                                 leaky_re_lu_41[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, None, None, 2 131072      add_18[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, None, None, 2 1024        conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_42 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_42[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, None, None, 5 2048        conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_43 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","add_19 (Add)                    (None, None, None, 5 0           add_18[0][0]                     \n","                                                                 leaky_re_lu_43[0][0]             \n","__________________________________________________________________________________________________\n","zero_padding2d_5 (ZeroPadding2D (None, None, None, 5 0           add_19[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, None, None, 1 4718592     zero_padding2d_5[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, None, None, 1 4096        conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_44 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_44[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, None, None, 5 2048        conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_45 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_45[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, None, None, 1 4096        conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_46 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","add_20 (Add)                    (None, None, None, 1 0           leaky_re_lu_44[0][0]             \n","                                                                 leaky_re_lu_46[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, None, None, 5 524288      add_20[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, None, None, 5 2048        conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_47 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_47[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, None, None, 1 4096        conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_48 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","add_21 (Add)                    (None, None, None, 1 0           add_20[0][0]                     \n","                                                                 leaky_re_lu_48[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, None, None, 5 524288      add_21[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, None, None, 5 2048        conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_49 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_49[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, None, None, 1 4096        conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_50 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","add_22 (Add)                    (None, None, None, 1 0           add_21[0][0]                     \n","                                                                 leaky_re_lu_50[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, None, None, 5 524288      add_22[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, None, None, 5 2048        conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_51 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_51[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, None, None, 1 4096        conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_52 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","add_23 (Add)                    (None, None, None, 1 0           add_22[0][0]                     \n","                                                                 leaky_re_lu_52[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, None, None, 5 524288      add_23[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_53 (BatchNo (None, None, None, 5 2048        conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_53 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_53[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_53[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_54 (BatchNo (None, None, None, 1 4096        conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_54 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_55 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_54[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_55 (BatchNo (None, None, None, 5 2048        conv2d_55[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_55 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_55[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_56 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_55[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_56 (BatchNo (None, None, None, 1 4096        conv2d_56[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_56 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_57 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_56[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_57 (BatchNo (None, None, None, 5 2048        conv2d_57[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_57 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_57[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_60 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_57[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_59 (BatchNo (None, None, None, 2 1024        conv2d_60[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_59 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_59[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, None, None, 2 0           leaky_re_lu_59[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, None, None, 7 0           up_sampling2d_1[0][0]            \n","                                                                 add_19[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_61 (Conv2D)              (None, None, None, 2 196608      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_60 (BatchNo (None, None, None, 2 1024        conv2d_61[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_60 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_60[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_62 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_60[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, None, None, 5 2048        conv2d_62[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_61 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_61[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_63 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_61[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_62 (BatchNo (None, None, None, 2 1024        conv2d_63[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_62 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_62[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_64 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_62[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_63 (BatchNo (None, None, None, 5 2048        conv2d_64[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_63 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_63[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_65 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_63[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_64 (BatchNo (None, None, None, 2 1024        conv2d_65[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_64 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_64[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_68 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_64[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_66 (BatchNo (None, None, None, 1 512         conv2d_68[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_66 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, None, None, 1 0           leaky_re_lu_66[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, None, None, 3 0           up_sampling2d_2[0][0]            \n","                                                                 add_11[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_69 (Conv2D)              (None, None, None, 1 49152       concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_67 (BatchNo (None, None, None, 1 512         conv2d_69[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_67 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_70 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_67[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_68 (BatchNo (None, None, None, 2 1024        conv2d_70[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_68 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_68[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_71 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_68[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_69 (BatchNo (None, None, None, 1 512         conv2d_71[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_69 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_72 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_69[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_70 (BatchNo (None, None, None, 2 1024        conv2d_72[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_70 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_70[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_73 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_70[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_71 (BatchNo (None, None, None, 1 512         conv2d_73[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_71 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_58 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_57[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_66 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_64[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_74 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_71[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_58 (BatchNo (None, None, None, 1 4096        conv2d_58[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_65 (BatchNo (None, None, None, 5 2048        conv2d_66[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_72 (BatchNo (None, None, None, 2 1024        conv2d_74[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_58 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_65 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_65[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_72 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_72[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_59 (Conv2D)              (None, None, None, 2 261375      leaky_re_lu_58[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_67 (Conv2D)              (None, None, None, 2 130815      leaky_re_lu_65[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_75 (Conv2D)              (None, None, None, 2 65535       leaky_re_lu_72[0][0]             \n","==================================================================================================\n","Total params: 62,001,757\n","Trainable params: 61,949,149\n","Non-trainable params: 52,608\n","__________________________________________________________________________________________________\n","None\n","Saved Keras weights to model_data/yolo_weights.h5\n","Read 62001757 of 62001757.0 from Darknet weights.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"swm6pA5w5xhu","executionInfo":{"status":"ok","timestamp":1612512722199,"user_tz":-540,"elapsed":3574,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"963e4306-418b-490f-c688-f05196b6ae99"},"source":["!cat /proc/uptime | awk '{print $1 /60 /60 \"hours\"}'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["0.0882556hours\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fqqI2cWD3tSV","executionInfo":{"status":"ok","timestamp":1612481104314,"user_tz":-540,"elapsed":826,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"2b1c0fad-806c-44be-83fa-0ce71eca3f0b"},"source":["cd .."],"execution_count":8,"outputs":[{"output_type":"stream","text":["/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"E6KMrJGBkj4v"},"source":["!python train.py"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YUhCECR6n717","executionInfo":{"status":"ok","timestamp":1612431795916,"user_tz":-540,"elapsed":9258476,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"1a8dea7b-13a8-4543-beda-bee702297941"},"source":["!python train.py"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","2021-02-04 07:08:59.024867: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","Create YOLOv3 model with 9 anchors and 2 classes.\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 21) vs (255, 1024, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((21,) vs (255,)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 21) vs (255, 512, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((21,) vs (255,)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 21) vs (255, 256, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((21,) vs (255,)).\n","  weight_values[i].shape))\n","Load weights model_data/yolo_weights.h5.\n","Freeze the first 249 layers of total 252 layers.\n","Train on 72 samples, val on 7 samples, with batch size 32.\n","Epoch 1/50\n","2/2 [==============================] - 192s 96s/step - loss: 6878.3701 - val_loss: 6504.5806\n","Epoch 2/50\n","2/2 [==============================] - 182s 91s/step - loss: 5532.0403 - val_loss: 4839.0259\n","Epoch 3/50\n","2/2 [==============================] - 183s 92s/step - loss: 4436.4104 - val_loss: 4085.4260\n","Epoch 4/50\n","2/2 [==============================] - 181s 90s/step - loss: 3549.2725 - val_loss: 3446.8281\n","Epoch 5/50\n","2/2 [==============================] - 183s 91s/step - loss: 2826.0353 - val_loss: 2804.8447\n","Epoch 6/50\n","2/2 [==============================] - 183s 91s/step - loss: 2272.8844 - val_loss: 2203.3508\n","Epoch 7/50\n","2/2 [==============================] - 182s 91s/step - loss: 1829.0524 - val_loss: 1758.1256\n","Epoch 8/50\n","2/2 [==============================] - 182s 91s/step - loss: 1482.5217 - val_loss: 1433.4076\n","Epoch 9/50\n","2/2 [==============================] - 182s 91s/step - loss: 1207.6050 - val_loss: 1241.0347\n","Epoch 10/50\n","2/2 [==============================] - 183s 91s/step - loss: 998.7964 - val_loss: 1020.1205\n","Epoch 11/50\n","2/2 [==============================] - 182s 91s/step - loss: 834.4568 - val_loss: 815.1273\n","Epoch 12/50\n","2/2 [==============================] - 183s 91s/step - loss: 704.5909 - val_loss: 689.8775\n","Epoch 13/50\n","2/2 [==============================] - 182s 91s/step - loss: 592.7798 - val_loss: 597.2714\n","Epoch 14/50\n","2/2 [==============================] - 182s 91s/step - loss: 516.5209 - val_loss: 538.9485\n","Epoch 15/50\n","2/2 [==============================] - 183s 91s/step - loss: 449.9955 - val_loss: 452.3132\n","Epoch 16/50\n","2/2 [==============================] - 182s 91s/step - loss: 404.0034 - val_loss: 413.0155\n","Epoch 17/50\n","2/2 [==============================] - 182s 91s/step - loss: 358.0578 - val_loss: 378.1577\n","Epoch 18/50\n","2/2 [==============================] - 182s 91s/step - loss: 317.7028 - val_loss: 338.9371\n","Epoch 19/50\n","2/2 [==============================] - 181s 91s/step - loss: 291.3840 - val_loss: 302.8178\n","Epoch 20/50\n","2/2 [==============================] - 182s 91s/step - loss: 263.4081 - val_loss: 274.8709\n","Epoch 21/50\n","2/2 [==============================] - 183s 92s/step - loss: 250.4251 - val_loss: 272.9661\n","Epoch 22/50\n","2/2 [==============================] - 183s 91s/step - loss: 229.8478 - val_loss: 247.8595\n","Epoch 23/50\n","2/2 [==============================] - 182s 91s/step - loss: 220.1539 - val_loss: 239.9834\n","Epoch 24/50\n","2/2 [==============================] - 182s 91s/step - loss: 206.2002 - val_loss: 213.6282\n","Epoch 25/50\n","2/2 [==============================] - 183s 91s/step - loss: 189.2532 - val_loss: 215.7583\n","Epoch 26/50\n","2/2 [==============================] - 183s 92s/step - loss: 183.5017 - val_loss: 204.2359\n","Epoch 27/50\n","2/2 [==============================] - 182s 91s/step - loss: 174.1043 - val_loss: 190.8386\n","Epoch 28/50\n","2/2 [==============================] - 183s 91s/step - loss: 171.0885 - val_loss: 176.8754\n","Epoch 29/50\n","2/2 [==============================] - 182s 91s/step - loss: 163.9722 - val_loss: 164.0165\n","Epoch 30/50\n","2/2 [==============================] - 183s 91s/step - loss: 157.6216 - val_loss: 167.1367\n","Epoch 31/50\n","2/2 [==============================] - 182s 91s/step - loss: 145.5526 - val_loss: 160.6149\n","Epoch 32/50\n","2/2 [==============================] - 183s 92s/step - loss: 148.2609 - val_loss: 154.4064\n","Epoch 33/50\n","2/2 [==============================] - 184s 92s/step - loss: 143.5632 - val_loss: 146.7920\n","Epoch 34/50\n","2/2 [==============================] - 183s 92s/step - loss: 132.3825 - val_loss: 150.9745\n","Epoch 35/50\n","2/2 [==============================] - 184s 92s/step - loss: 132.5081 - val_loss: 140.6505\n","Epoch 36/50\n","2/2 [==============================] - 183s 91s/step - loss: 128.4354 - val_loss: 134.4959\n","Epoch 37/50\n","2/2 [==============================] - 182s 91s/step - loss: 127.6848 - val_loss: 129.9942\n","Epoch 38/50\n","2/2 [==============================] - 182s 91s/step - loss: 122.2470 - val_loss: 131.5267\n","Epoch 39/50\n","2/2 [==============================] - 183s 92s/step - loss: 117.6550 - val_loss: 127.4892\n","Epoch 40/50\n","2/2 [==============================] - 184s 92s/step - loss: 116.3886 - val_loss: 123.3896\n","Epoch 41/50\n","2/2 [==============================] - 183s 92s/step - loss: 111.3814 - val_loss: 120.0206\n","Epoch 42/50\n","2/2 [==============================] - 183s 92s/step - loss: 106.5139 - val_loss: 117.8688\n","Epoch 43/50\n","2/2 [==============================] - 182s 91s/step - loss: 100.9654 - val_loss: 117.2569\n","Epoch 44/50\n","2/2 [==============================] - 183s 91s/step - loss: 106.5215 - val_loss: 111.9460\n","Epoch 45/50\n","2/2 [==============================] - 183s 91s/step - loss: 100.5710 - val_loss: 114.9223\n","Epoch 46/50\n","2/2 [==============================] - 184s 92s/step - loss: 101.4712 - val_loss: 106.5047\n","Epoch 47/50\n","2/2 [==============================] - 183s 92s/step - loss: 93.9575 - val_loss: 109.7743\n","Epoch 48/50\n","2/2 [==============================] - 184s 92s/step - loss: 96.8869 - val_loss: 104.2146\n","Epoch 49/50\n","2/2 [==============================] - 183s 92s/step - loss: 92.7799 - val_loss: 105.9345\n","Epoch 50/50\n","2/2 [==============================] - 183s 92s/step - loss: 91.3800 - val_loss: 100.7073\n","Unfreeze all of the layers.\n","Train on 72 samples, val on 7 samples, with batch size 32.\n","Epoch 51/100\n","^C\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"riKBVk55bWEs","executionInfo":{"status":"ok","timestamp":1612439385985,"user_tz":-540,"elapsed":6978778,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"f05d0101-ad82-497a-ec58-f51bb08f4c0a"},"source":["!python train.py"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","2021-02-04 09:53:29.006461: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","Create YOLOv3 model with 9 anchors and 2 classes.\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 21) vs (255, 1024, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((21,) vs (255,)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 21) vs (255, 512, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((21,) vs (255,)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 21) vs (255, 256, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((21,) vs (255,)).\n","  weight_values[i].shape))\n","Load weights model_data/yolo_weights.h5.\n","Freeze the first 249 layers of total 252 layers.\n","Train on 72 samples, val on 7 samples, with batch size 8.\n","Epoch 1/50\n","9/9 [==============================] - 148s 16s/step - loss: 4119.0655 - val_loss: 1926.9917\n","Epoch 2/50\n","9/9 [==============================] - 145s 16s/step - loss: 1492.0623 - val_loss: 720.9141\n","Epoch 3/50\n","9/9 [==============================] - 144s 16s/step - loss: 626.2839 - val_loss: 390.2602\n","Epoch 4/50\n","9/9 [==============================] - 144s 16s/step - loss: 328.2489 - val_loss: 231.5833\n","Epoch 5/50\n","9/9 [==============================] - 143s 16s/step - loss: 217.7656 - val_loss: 157.3908\n","Epoch 6/50\n","9/9 [==============================] - 143s 16s/step - loss: 163.1788 - val_loss: 138.5878\n","Epoch 7/50\n","9/9 [==============================] - 143s 16s/step - loss: 133.9242 - val_loss: 106.9564\n","Epoch 8/50\n","9/9 [==============================] - 144s 16s/step - loss: 114.7207 - val_loss: 123.5858\n","Epoch 9/50\n","9/9 [==============================] - 143s 16s/step - loss: 100.6774 - val_loss: 90.3059\n","Epoch 10/50\n","9/9 [==============================] - 143s 16s/step - loss: 89.1917 - val_loss: 66.3425\n","Epoch 11/50\n","9/9 [==============================] - 143s 16s/step - loss: 82.5488 - val_loss: 69.8507\n","Epoch 12/50\n","9/9 [==============================] - 143s 16s/step - loss: 77.3238 - val_loss: 69.8451\n","Epoch 13/50\n","9/9 [==============================] - 143s 16s/step - loss: 69.7939 - val_loss: 60.0611\n","Epoch 14/50\n","9/9 [==============================] - 143s 16s/step - loss: 67.6479 - val_loss: 63.8632\n","Epoch 15/50\n","9/9 [==============================] - 143s 16s/step - loss: 60.6208 - val_loss: 64.3957\n","Epoch 16/50\n","9/9 [==============================] - 143s 16s/step - loss: 56.8269 - val_loss: 53.2128\n","Epoch 17/50\n","9/9 [==============================] - 143s 16s/step - loss: 54.2105 - val_loss: 50.2993\n","Epoch 18/50\n","9/9 [==============================] - 146s 16s/step - loss: 49.6986 - val_loss: 54.4947\n","Epoch 19/50\n","9/9 [==============================] - 142s 16s/step - loss: 47.5064 - val_loss: 64.3303\n","Epoch 20/50\n","9/9 [==============================] - 138s 15s/step - loss: 44.9458 - val_loss: 37.7818\n","Epoch 21/50\n","9/9 [==============================] - 135s 15s/step - loss: 42.1865 - val_loss: 35.5515\n","Epoch 22/50\n","9/9 [==============================] - 134s 15s/step - loss: 41.7562 - val_loss: 49.2887\n","Epoch 23/50\n","9/9 [==============================] - 134s 15s/step - loss: 39.1121 - val_loss: 44.1549\n","Epoch 24/50\n","9/9 [==============================] - 133s 15s/step - loss: 38.8416 - val_loss: 40.3144\n","Epoch 25/50\n","9/9 [==============================] - 133s 15s/step - loss: 35.7501 - val_loss: 35.0106\n","Epoch 26/50\n","9/9 [==============================] - 133s 15s/step - loss: 36.1371 - val_loss: 32.7943\n","Epoch 27/50\n","9/9 [==============================] - 133s 15s/step - loss: 33.4341 - val_loss: 29.9852\n","Epoch 28/50\n","9/9 [==============================] - 133s 15s/step - loss: 33.7784 - val_loss: 31.7398\n","Epoch 29/50\n","9/9 [==============================] - 133s 15s/step - loss: 32.4077 - val_loss: 30.0808\n","Epoch 30/50\n","9/9 [==============================] - 134s 15s/step - loss: 30.5615 - val_loss: 27.1613\n","Epoch 31/50\n","9/9 [==============================] - 137s 15s/step - loss: 29.6387 - val_loss: 30.6607\n","Epoch 32/50\n","9/9 [==============================] - 134s 15s/step - loss: 28.7532 - val_loss: 29.9864\n","Epoch 33/50\n","9/9 [==============================] - 133s 15s/step - loss: 28.3465 - val_loss: 23.7400\n","Epoch 34/50\n","9/9 [==============================] - 136s 15s/step - loss: 27.7938 - val_loss: 27.0865\n","Epoch 35/50\n","9/9 [==============================] - 136s 15s/step - loss: 26.6921 - val_loss: 28.0879\n","Epoch 36/50\n","9/9 [==============================] - 133s 15s/step - loss: 25.9440 - val_loss: 24.3382\n","Epoch 37/50\n","9/9 [==============================] - 132s 15s/step - loss: 26.1397 - val_loss: 26.6521\n","Epoch 38/50\n","9/9 [==============================] - 133s 15s/step - loss: 25.2699 - val_loss: 24.6546\n","Epoch 39/50\n","9/9 [==============================] - 132s 15s/step - loss: 24.6811 - val_loss: 24.2249\n","Epoch 40/50\n","9/9 [==============================] - 132s 15s/step - loss: 24.1311 - val_loss: 22.5218\n","Epoch 41/50\n","9/9 [==============================] - 132s 15s/step - loss: 23.9359 - val_loss: 24.7180\n","Epoch 42/50\n","9/9 [==============================] - 134s 15s/step - loss: 22.9112 - val_loss: 18.2579\n","Epoch 43/50\n","9/9 [==============================] - 133s 15s/step - loss: 23.3769 - val_loss: 21.3135\n","Epoch 44/50\n","9/9 [==============================] - 133s 15s/step - loss: 22.7196 - val_loss: 23.1775\n","Epoch 45/50\n","9/9 [==============================] - 132s 15s/step - loss: 21.9122 - val_loss: 21.6271\n","Epoch 46/50\n","9/9 [==============================] - 132s 15s/step - loss: 21.3630 - val_loss: 22.0777\n","Epoch 47/50\n","9/9 [==============================] - 132s 15s/step - loss: 20.8927 - val_loss: 19.2174\n","Epoch 48/50\n","9/9 [==============================] - 132s 15s/step - loss: 21.3274 - val_loss: 21.8553\n","Epoch 49/50\n","9/9 [==============================] - 132s 15s/step - loss: 20.8351 - val_loss: 19.7234\n","Epoch 50/50\n","9/9 [==============================] - 132s 15s/step - loss: 20.2216 - val_loss: 20.9461\n","Unfreeze all of the layers.\n","Train on 72 samples, val on 7 samples, with batch size 32.\n","Epoch 51/100\n","^C\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YKBp6RLebtfU","executionInfo":{"status":"ok","timestamp":1612432027454,"user_tz":-540,"elapsed":750,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"499739f5-99b2-4745-efe2-16851610162c"},"source":["!nvidia-smi"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Thu Feb  4 09:47:07 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.39       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DBsX60xw6RN2","outputId":"36512306-8a72-4f66-c2c4-44afbed3ba09"},"source":["!python train.py\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","2021-02-04 11:59:24.598313: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","Create YOLOv3 model with 9 anchors and 2 classes.\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 21) vs (255, 1024, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((21,) vs (255,)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 21) vs (255, 512, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((21,) vs (255,)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 21) vs (255, 256, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((21,) vs (255,)).\n","  weight_values[i].shape))\n","Load weights model_data/yolo_weights.h5.\n","Freeze the first 249 layers of total 252 layers.\n","Train on 72 samples, val on 7 samples, with batch size 8.\n","Epoch 1/50\n","9/9 [==============================] - 144s 16s/step - loss: 3301.5607 - val_loss: 1749.5834\n","Epoch 2/50\n","9/9 [==============================] - 140s 16s/step - loss: 1183.5996 - val_loss: 744.6461\n","Epoch 3/50\n","9/9 [==============================] - 140s 16s/step - loss: 506.8301 - val_loss: 287.4328\n","Epoch 4/50\n","9/9 [==============================] - 134s 15s/step - loss: 281.0933 - val_loss: 250.3244\n","Epoch 5/50\n","9/9 [==============================] - 133s 15s/step - loss: 189.9919 - val_loss: 163.5657\n","Epoch 6/50\n","9/9 [==============================] - 133s 15s/step - loss: 147.1742 - val_loss: 134.8955\n","Epoch 7/50\n","9/9 [==============================] - 132s 15s/step - loss: 124.5515 - val_loss: 86.1749\n","Epoch 8/50\n","9/9 [==============================] - 133s 15s/step - loss: 102.9518 - val_loss: 99.9607\n","Epoch 9/50\n","9/9 [==============================] - 132s 15s/step - loss: 90.9064 - val_loss: 97.6713\n","Epoch 10/50\n","9/9 [==============================] - 132s 15s/step - loss: 83.3908 - val_loss: 81.7741\n","Epoch 11/50\n","9/9 [==============================] - 132s 15s/step - loss: 75.6138 - val_loss: 90.9947\n","Epoch 12/50\n","9/9 [==============================] - 131s 15s/step - loss: 68.3137 - val_loss: 81.5537\n","Epoch 13/50\n","9/9 [==============================] - 131s 15s/step - loss: 63.5975 - val_loss: 70.7942\n","Epoch 14/50\n","9/9 [==============================] - 130s 14s/step - loss: 59.8513 - val_loss: 71.7313\n","Epoch 15/50\n","9/9 [==============================] - 131s 15s/step - loss: 55.0436 - val_loss: 57.5458\n","Epoch 16/50\n","9/9 [==============================] - 131s 15s/step - loss: 52.1862 - val_loss: 63.6985\n","Epoch 17/50\n","9/9 [==============================] - 131s 15s/step - loss: 49.8237 - val_loss: 49.7630\n","Epoch 18/50\n","9/9 [==============================] - 130s 14s/step - loss: 46.0120 - val_loss: 47.5027\n","Epoch 19/50\n","9/9 [==============================] - 131s 15s/step - loss: 43.8926 - val_loss: 31.3086\n","Epoch 20/50\n","9/9 [==============================] - 131s 15s/step - loss: 41.6503 - val_loss: 37.2690\n","Epoch 21/50\n","9/9 [==============================] - 131s 15s/step - loss: 38.7653 - val_loss: 40.0733\n","Epoch 22/50\n","9/9 [==============================] - 132s 15s/step - loss: 39.0703 - val_loss: 39.0533\n","Epoch 23/50\n","9/9 [==============================] - 131s 15s/step - loss: 36.1114 - val_loss: 39.2126\n","Epoch 24/50\n","9/9 [==============================] - 132s 15s/step - loss: 35.6130 - val_loss: 32.5137\n","Epoch 25/50\n","9/9 [==============================] - 131s 15s/step - loss: 32.3076 - val_loss: 38.1793\n","Epoch 26/50\n","9/9 [==============================] - 131s 15s/step - loss: 32.7056 - val_loss: 30.9365\n","Epoch 27/50\n","9/9 [==============================] - 131s 15s/step - loss: 31.2407 - val_loss: 36.6360\n","Epoch 28/50\n","9/9 [==============================] - 131s 15s/step - loss: 30.3633 - val_loss: 23.4095\n","Epoch 29/50\n","9/9 [==============================] - 131s 15s/step - loss: 29.5026 - val_loss: 31.4194\n","Epoch 30/50\n","9/9 [==============================] - 131s 15s/step - loss: 28.5214 - val_loss: 27.7572\n","Epoch 31/50\n","9/9 [==============================] - 131s 15s/step - loss: 28.1112 - val_loss: 31.7730\n","Epoch 32/50\n","9/9 [==============================] - 131s 15s/step - loss: 27.5827 - val_loss: 27.5564\n","Epoch 33/50\n","9/9 [==============================] - 131s 15s/step - loss: 26.3137 - val_loss: 30.2779\n","Epoch 34/50\n","9/9 [==============================] - 131s 15s/step - loss: 24.7042 - val_loss: 24.6492\n","Epoch 35/50\n","9/9 [==============================] - 131s 15s/step - loss: 24.9430 - val_loss: 27.9435\n","Epoch 36/50\n","9/9 [==============================] - 131s 15s/step - loss: 23.8418 - val_loss: 21.6241\n","Epoch 37/50\n","9/9 [==============================] - 131s 15s/step - loss: 23.8627 - val_loss: 21.4191\n","Epoch 38/50\n","9/9 [==============================] - 131s 15s/step - loss: 23.4420 - val_loss: 22.5577\n","Epoch 39/50\n","9/9 [==============================] - 131s 15s/step - loss: 23.2629 - val_loss: 21.1474\n","Epoch 40/50\n","9/9 [==============================] - 131s 15s/step - loss: 22.9691 - val_loss: 20.7030\n","Epoch 41/50\n","9/9 [==============================] - 131s 15s/step - loss: 22.2267 - val_loss: 21.1433\n","Epoch 42/50\n","9/9 [==============================] - 131s 15s/step - loss: 21.8793 - val_loss: 20.3609\n","Epoch 43/50\n","9/9 [==============================] - 131s 15s/step - loss: 21.7615 - val_loss: 25.5281\n","Epoch 44/50\n","9/9 [==============================] - 130s 14s/step - loss: 20.5918 - val_loss: 22.1922\n","Epoch 45/50\n","9/9 [==============================] - 131s 15s/step - loss: 20.3345 - val_loss: 22.3891\n","Epoch 46/50\n","9/9 [==============================] - 131s 15s/step - loss: 20.3587 - val_loss: 19.2340\n","Epoch 47/50\n","9/9 [==============================] - 131s 15s/step - loss: 19.7718 - val_loss: 21.3925\n","Epoch 48/50\n","9/9 [==============================] - 131s 15s/step - loss: 19.7395 - val_loss: 19.6634\n","Epoch 49/50\n","9/9 [==============================] - 130s 14s/step - loss: 18.9731 - val_loss: 21.4236\n","Epoch 50/50\n","9/9 [==============================] - 131s 15s/step - loss: 19.3355 - val_loss: 17.0813\n","Unfreeze all of the layers.\n","Train on 72 samples, val on 7 samples, with batch size 8.\n","Epoch 51/100\n","9/9 [==============================] - 365s 41s/step - loss: 12.5841 - val_loss: 13.6415\n","Epoch 52/100\n","9/9 [==============================] - 353s 39s/step - loss: 10.8019 - val_loss: 11.8090\n","Epoch 53/100\n","9/9 [==============================] - 353s 39s/step - loss: 10.4850 - val_loss: 10.8558\n","Epoch 54/100\n","9/9 [==============================] - 354s 39s/step - loss: 10.2907 - val_loss: 10.4738\n","Epoch 55/100\n","9/9 [==============================] - 355s 39s/step - loss: 10.1627 - val_loss: 10.2723\n","Epoch 56/100\n","9/9 [==============================] - 352s 39s/step - loss: 10.0529 - val_loss: 10.1178\n","Epoch 57/100\n","9/9 [==============================] - 352s 39s/step - loss: 9.9704 - val_loss: 9.9976\n","Epoch 58/100\n","9/9 [==============================] - 353s 39s/step - loss: 9.8928 - val_loss: 9.9089\n","Epoch 59/100\n","9/9 [==============================] - 353s 39s/step - loss: 9.8328 - val_loss: 9.8353\n","Epoch 60/100\n","9/9 [==============================] - 352s 39s/step - loss: 9.7761 - val_loss: 9.7788\n","Epoch 61/100\n","9/9 [==============================] - 352s 39s/step - loss: 9.7232 - val_loss: 9.7130\n","Epoch 62/100\n","9/9 [==============================] - 353s 39s/step - loss: 9.6654 - val_loss: 9.6715\n","Epoch 63/100\n","9/9 [==============================] - 353s 39s/step - loss: 9.6188 - val_loss: 9.6059\n","Epoch 64/100\n","9/9 [==============================] - 353s 39s/step - loss: 9.5702 - val_loss: 9.5698\n","Epoch 65/100\n","9/9 [==============================] - 352s 39s/step - loss: 9.5242 - val_loss: 9.5184\n","Epoch 66/100\n","9/9 [==============================] - 352s 39s/step - loss: 9.4797 - val_loss: 9.4677\n","Epoch 67/100\n","9/9 [==============================] - 352s 39s/step - loss: 9.4358 - val_loss: 9.4291\n","Epoch 68/100\n","9/9 [==============================] - 351s 39s/step - loss: 9.3940 - val_loss: 9.3785\n","Epoch 69/100\n","9/9 [==============================] - 350s 39s/step - loss: 9.3496 - val_loss: 9.3336\n","Epoch 70/100\n","9/9 [==============================] - 351s 39s/step - loss: 9.3101 - val_loss: 9.2931\n","Epoch 71/100\n","9/9 [==============================] - 350s 39s/step - loss: 9.2689 - val_loss: 9.2534\n","Epoch 72/100\n","9/9 [==============================] - 352s 39s/step - loss: 9.2272 - val_loss: 9.2050\n","Epoch 73/100\n","9/9 [==============================] - 352s 39s/step - loss: 9.1861 - val_loss: 9.1668\n","Epoch 74/100\n","9/9 [==============================] - 351s 39s/step - loss: 9.1486 - val_loss: 9.1307\n","Epoch 75/100\n","9/9 [==============================] - 351s 39s/step - loss: 9.1073 - val_loss: 9.0896\n","Epoch 76/100\n","9/9 [==============================] - 351s 39s/step - loss: 9.0668 - val_loss: 9.0505\n","Epoch 77/100\n","9/9 [==============================] - 352s 39s/step - loss: 9.0271 - val_loss: 9.0120\n","Epoch 78/100\n","9/9 [==============================] - 352s 39s/step - loss: 8.9887 - val_loss: 8.9737\n","Epoch 79/100\n","9/9 [==============================] - 351s 39s/step - loss: 8.9490 - val_loss: 8.9343\n","Epoch 80/100\n","9/9 [==============================] - 352s 39s/step - loss: 8.9082 - val_loss: 8.8920\n","Epoch 81/100\n","9/9 [==============================] - 351s 39s/step - loss: 8.8694 - val_loss: 8.8551\n","Epoch 82/100\n","4/9 [============>.................] - ETA: 3:07 - loss: 8.8432"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FqpbNeQe9_cy"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DD7pS-qVYLMF","executionInfo":{"status":"ok","timestamp":1612511219022,"user_tz":-540,"elapsed":16680941,"user":{"displayName":"T.O. S","photoUrl":"","userId":"15581531355235433732"}},"outputId":"34aac0c2-cfe3-4a0d-def6-96b69320b0f4"},"source":["!python train.py\r\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","2021-02-05 00:42:47.445873: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","Create YOLOv3 model with 9 anchors and 1 classes.\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 18) vs (255, 1024, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((18,) vs (255,)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 18) vs (255, 512, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((18,) vs (255,)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 18) vs (255, 256, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((18,) vs (255,)).\n","  weight_values[i].shape))\n","Load weights model_data/yolo_weights.h5.\n","Freeze the first 249 layers of total 252 layers.\n","Train on 72 samples, val on 7 samples, with batch size 8.\n","Epoch 1/50\n","9/9 [==============================] - 140s 16s/step - loss: 1622.3464 - val_loss: 803.5317\n","Epoch 2/50\n","9/9 [==============================] - 138s 15s/step - loss: 450.2984 - val_loss: 294.7910\n","Epoch 3/50\n","9/9 [==============================] - 138s 15s/step - loss: 189.6409 - val_loss: 149.6266\n","Epoch 4/50\n","9/9 [==============================] - 138s 15s/step - loss: 111.1760 - val_loss: 105.3733\n","Epoch 5/50\n","9/9 [==============================] - 139s 15s/step - loss: 83.6657 - val_loss: 97.3598\n","Epoch 6/50\n","9/9 [==============================] - 139s 15s/step - loss: 68.2357 - val_loss: 67.5207\n","Epoch 7/50\n","9/9 [==============================] - 137s 15s/step - loss: 59.2674 - val_loss: 64.8520\n","Epoch 8/50\n","9/9 [==============================] - 134s 15s/step - loss: 52.9866 - val_loss: 52.2089\n","Epoch 9/50\n","9/9 [==============================] - 134s 15s/step - loss: 46.9328 - val_loss: 47.8571\n","Epoch 10/50\n","9/9 [==============================] - 132s 15s/step - loss: 43.3103 - val_loss: 43.6120\n","Epoch 11/50\n","9/9 [==============================] - 131s 15s/step - loss: 38.7040 - val_loss: 41.9666\n","Epoch 12/50\n","9/9 [==============================] - 132s 15s/step - loss: 37.9850 - val_loss: 39.6786\n","Epoch 13/50\n","9/9 [==============================] - 135s 15s/step - loss: 35.0822 - val_loss: 40.6234\n","Epoch 14/50\n","9/9 [==============================] - 137s 15s/step - loss: 33.4919 - val_loss: 37.1699\n","Epoch 15/50\n","9/9 [==============================] - 143s 16s/step - loss: 31.6926 - val_loss: 33.3570\n","Epoch 16/50\n","9/9 [==============================] - 142s 16s/step - loss: 30.5007 - val_loss: 33.8270\n","Epoch 17/50\n","9/9 [==============================] - 140s 16s/step - loss: 29.4416 - val_loss: 30.7936\n","Epoch 18/50\n","9/9 [==============================] - 141s 16s/step - loss: 27.7243 - val_loss: 30.4156\n","Epoch 19/50\n","9/9 [==============================] - 141s 16s/step - loss: 25.8538 - val_loss: 32.3789\n","Epoch 20/50\n","9/9 [==============================] - 140s 16s/step - loss: 25.6961 - val_loss: 32.7690\n","Epoch 21/50\n","9/9 [==============================] - 140s 16s/step - loss: 24.6493 - val_loss: 29.0763\n","Epoch 22/50\n","9/9 [==============================] - 141s 16s/step - loss: 23.6336 - val_loss: 27.8705\n","Epoch 23/50\n","9/9 [==============================] - 141s 16s/step - loss: 22.8652 - val_loss: 24.3478\n","Epoch 24/50\n","9/9 [==============================] - 140s 16s/step - loss: 21.9048 - val_loss: 23.4622\n","Epoch 25/50\n","9/9 [==============================] - 139s 15s/step - loss: 21.2558 - val_loss: 22.6126\n","Epoch 26/50\n","9/9 [==============================] - 138s 15s/step - loss: 21.7186 - val_loss: 21.3824\n","Epoch 27/50\n","9/9 [==============================] - 140s 16s/step - loss: 21.4515 - val_loss: 24.2427\n","Epoch 28/50\n","9/9 [==============================] - 138s 15s/step - loss: 20.2898 - val_loss: 24.7406\n","Epoch 29/50\n","9/9 [==============================] - 136s 15s/step - loss: 19.9093 - val_loss: 20.6570\n","Epoch 30/50\n","9/9 [==============================] - 136s 15s/step - loss: 19.1179 - val_loss: 19.7966\n","Epoch 31/50\n","9/9 [==============================] - 136s 15s/step - loss: 18.8877 - val_loss: 21.2751\n","Epoch 32/50\n","9/9 [==============================] - 137s 15s/step - loss: 18.4313 - val_loss: 19.8573\n","Epoch 33/50\n","9/9 [==============================] - 139s 15s/step - loss: 17.9398 - val_loss: 19.5986\n","Epoch 34/50\n","9/9 [==============================] - 136s 15s/step - loss: 17.7776 - val_loss: 17.2984\n","Epoch 35/50\n","9/9 [==============================] - 137s 15s/step - loss: 16.6662 - val_loss: 18.2085\n","Epoch 36/50\n","9/9 [==============================] - 135s 15s/step - loss: 17.0735 - val_loss: 18.1602\n","Epoch 37/50\n","9/9 [==============================] - 137s 15s/step - loss: 16.8040 - val_loss: 20.5676\n","Epoch 38/50\n","9/9 [==============================] - 138s 15s/step - loss: 16.6139 - val_loss: 18.4180\n","Epoch 39/50\n","9/9 [==============================] - 138s 15s/step - loss: 16.6910 - val_loss: 17.3799\n","Epoch 40/50\n","9/9 [==============================] - 140s 16s/step - loss: 16.3578 - val_loss: 16.8357\n","Epoch 41/50\n","9/9 [==============================] - 139s 15s/step - loss: 15.6456 - val_loss: 16.1092\n","Epoch 42/50\n","9/9 [==============================] - 137s 15s/step - loss: 15.8636 - val_loss: 16.3847\n","Epoch 43/50\n","9/9 [==============================] - 137s 15s/step - loss: 15.8009 - val_loss: 17.0671\n","Epoch 44/50\n","9/9 [==============================] - 137s 15s/step - loss: 15.2461 - val_loss: 16.6848\n","Epoch 45/50\n","9/9 [==============================] - 134s 15s/step - loss: 15.2077 - val_loss: 15.8411\n","Epoch 46/50\n","9/9 [==============================] - 134s 15s/step - loss: 15.0859 - val_loss: 16.8542\n","Epoch 47/50\n","9/9 [==============================] - 133s 15s/step - loss: 14.9469 - val_loss: 15.4571\n","Epoch 48/50\n","9/9 [==============================] - 132s 15s/step - loss: 14.6307 - val_loss: 14.3832\n","Epoch 49/50\n","9/9 [==============================] - 132s 15s/step - loss: 14.6153 - val_loss: 14.9535\n","Epoch 50/50\n","9/9 [==============================] - 131s 15s/step - loss: 14.4212 - val_loss: 14.5052\n","Unfreeze all of the layers.\n","Train on 72 samples, val on 7 samples, with batch size 8.\n","Epoch 51/100\n","9/9 [==============================] - 366s 41s/step - loss: 11.1150 - val_loss: 11.5456\n","Epoch 52/100\n","9/9 [==============================] - 356s 40s/step - loss: 10.1649 - val_loss: 10.5238\n","Epoch 53/100\n","9/9 [==============================] - 354s 39s/step - loss: 9.9913 - val_loss: 10.1774\n","Epoch 54/100\n","9/9 [==============================] - 352s 39s/step - loss: 9.8938 - val_loss: 9.9779\n","Epoch 55/100\n","9/9 [==============================] - 352s 39s/step - loss: 9.8092 - val_loss: 9.8629\n","Epoch 56/100\n","9/9 [==============================] - 352s 39s/step - loss: 9.7421 - val_loss: 9.7745\n","Epoch 57/100\n","9/9 [==============================] - 356s 40s/step - loss: 9.6745 - val_loss: 9.6924\n","Epoch 58/100\n","9/9 [==============================] - 371s 41s/step - loss: 9.6221 - val_loss: 9.6221\n","Epoch 59/100\n","9/9 [==============================] - 379s 42s/step - loss: 9.5619 - val_loss: 9.5541\n","Epoch 60/100\n","9/9 [==============================] - 379s 42s/step - loss: 9.5083 - val_loss: 9.4887\n","Epoch 61/100\n","9/9 [==============================] - 383s 43s/step - loss: 9.4581 - val_loss: 9.4387\n","Epoch 62/100\n","9/9 [==============================] - 383s 43s/step - loss: 9.3994 - val_loss: 9.3875\n","Epoch 63/100\n","9/9 [==============================] - 372s 41s/step - loss: 9.3490 - val_loss: 9.3316\n","Epoch 64/100\n","9/9 [==============================] - 362s 40s/step - loss: 9.2954 - val_loss: 9.2789\n","Epoch 65/100\n","9/9 [==============================] - 358s 40s/step - loss: 9.2407 - val_loss: 9.2234\n","Epoch 66/100\n","9/9 [==============================] - 357s 40s/step - loss: 9.1907 - val_loss: 9.1645\n","Epoch 67/100\n","9/9 [==============================] - 359s 40s/step - loss: 9.1368 - val_loss: 9.1125\n","Epoch 68/100\n","9/9 [==============================] - 372s 41s/step - loss: 9.0815 - val_loss: 9.0613\n","Epoch 69/100\n","9/9 [==============================] - 374s 42s/step - loss: 9.0325 - val_loss: 9.0070\n","Epoch 70/100\n","9/9 [==============================] - 380s 42s/step - loss: 8.9740 - val_loss: 8.9533\n","Epoch 71/100\n","9/9 [==============================] - 379s 42s/step - loss: 8.9196 - val_loss: 8.8996\n","Epoch 72/100\n","9/9 [==============================] - 380s 42s/step - loss: 8.8643 - val_loss: 8.8395\n","Epoch 73/100\n","9/9 [==============================] - 382s 42s/step - loss: 8.8096 - val_loss: 8.7853\n","Epoch 74/100\n","9/9 [==============================] - 385s 43s/step - loss: 8.7553 - val_loss: 8.7299\n","Epoch 75/100\n","9/9 [==============================] - 385s 43s/step - loss: 8.7001 - val_loss: 8.6775\n","Epoch 76/100\n","9/9 [==============================] - 387s 43s/step - loss: 8.6441 - val_loss: 8.6202\n","Epoch 77/100\n","9/9 [==============================] - 385s 43s/step - loss: 8.5880 - val_loss: 8.5635\n","Epoch 78/100\n","9/9 [==============================] - 387s 43s/step - loss: 8.5337 - val_loss: 8.5080\n","Epoch 79/100\n","9/9 [==============================] - 387s 43s/step - loss: 8.4767 - val_loss: 8.4518\n","Epoch 80/100\n","9/9 [==============================] - 386s 43s/step - loss: 8.4213 - val_loss: 8.3951\n","Epoch 81/100\n","9/9 [==============================] - 385s 43s/step - loss: 8.3648 - val_loss: 8.3381\n","Epoch 82/100\n","9/9 [==============================] - 387s 43s/step - loss: 8.3093 - val_loss: 8.2811\n","Epoch 83/100\n","9/9 [==============================] - 386s 43s/step - loss: 8.2529 - val_loss: 8.2262\n","Epoch 84/100\n","9/9 [==============================] - 385s 43s/step - loss: 8.1955 - val_loss: 8.1696\n","Epoch 85/100\n","9/9 [==============================] - 382s 42s/step - loss: 8.1394 - val_loss: 8.1116\n","Epoch 86/100\n","9/9 [==============================] - 366s 41s/step - loss: 8.0825 - val_loss: 8.0563\n","Epoch 87/100\n","9/9 [==============================] - 362s 40s/step - loss: 8.0259 - val_loss: 7.9994\n","Epoch 88/100\n","9/9 [==============================] - 364s 40s/step - loss: 7.9689 - val_loss: 7.9427\n","Epoch 89/100\n","9/9 [==============================] - 363s 40s/step - loss: 7.9121 - val_loss: 7.8853\n","Epoch 90/100\n","9/9 [==============================] - 360s 40s/step - loss: 7.8558 - val_loss: 7.8294\n","Epoch 91/100\n","9/9 [==============================] - 362s 40s/step - loss: 7.8001 - val_loss: 7.7714\n","Epoch 92/100\n","9/9 [==============================] - 360s 40s/step - loss: 7.7429 - val_loss: 7.7160\n","Epoch 93/100\n","9/9 [==============================] - 361s 40s/step - loss: 7.6855 - val_loss: 7.6591\n","Epoch 94/100\n","9/9 [==============================] - 362s 40s/step - loss: 7.6296 - val_loss: 7.6018\n","Epoch 95/100\n","9/9 [==============================] - 366s 41s/step - loss: 7.5726 - val_loss: 7.5459\n","Epoch 96/100\n","9/9 [==============================] - 360s 40s/step - loss: 7.5171 - val_loss: 7.4895\n","Epoch 97/100\n","9/9 [==============================] - 360s 40s/step - loss: 7.4598 - val_loss: 7.4332\n","Epoch 98/100\n","9/9 [==============================] - 367s 41s/step - loss: 7.4037 - val_loss: 7.3774\n","Epoch 99/100\n","9/9 [==============================] - 362s 40s/step - loss: 7.3480 - val_loss: 7.3210\n","Epoch 100/100\n","9/9 [==============================] - 374s 42s/step - loss: 7.2922 - val_loss: 7.2651\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7op9wc4dU-U3","outputId":"f4c71673-a060-49d5-af90-e1c264f2d4d8"},"source":["!python train.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","2021-02-05 08:37:03.887574: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","Create YOLOv3 model with 9 anchors and 2 classes.\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 21) vs (255, 1024, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((21,) vs (255,)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 21) vs (255, 512, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((21,) vs (255,)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 21) vs (255, 256, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((21,) vs (255,)).\n","  weight_values[i].shape))\n","Load weights model_data/yolo_weights.h5.\n","Freeze the first 249 layers of total 252 layers.\n","Train on 72 samples, val on 7 samples, with batch size 8.\n","Epoch 1/50\n","9/9 [==============================] - 163s 18s/step - loss: 2521.5920 - val_loss: 1470.8851\n","Epoch 2/50\n","9/9 [==============================] - 160s 18s/step - loss: 731.4463 - val_loss: 566.6074\n","Epoch 3/50\n","9/9 [==============================] - 160s 18s/step - loss: 285.3450 - val_loss: 286.1724\n","Epoch 4/50\n","9/9 [==============================] - 160s 18s/step - loss: 171.7038 - val_loss: 176.4529\n","Epoch 5/50\n","9/9 [==============================] - 159s 18s/step - loss: 117.7218 - val_loss: 153.3329\n","Epoch 6/50\n","9/9 [==============================] - 156s 17s/step - loss: 93.1889 - val_loss: 108.2396\n","Epoch 7/50\n","9/9 [==============================] - 157s 17s/step - loss: 82.4673 - val_loss: 86.5942\n","Epoch 8/50\n","9/9 [==============================] - 157s 17s/step - loss: 72.2096 - val_loss: 77.9505\n","Epoch 9/50\n","9/9 [==============================] - 158s 18s/step - loss: 64.2304 - val_loss: 74.8135\n","Epoch 10/50\n","9/9 [==============================] - 158s 18s/step - loss: 58.8613 - val_loss: 74.1224\n","Epoch 11/50\n","9/9 [==============================] - 157s 17s/step - loss: 54.2336 - val_loss: 68.5903\n","Epoch 12/50\n","9/9 [==============================] - 157s 17s/step - loss: 50.4761 - val_loss: 62.4692\n","Epoch 13/50\n","9/9 [==============================] - 156s 17s/step - loss: 46.4032 - val_loss: 56.2642\n","Epoch 14/50\n","9/9 [==============================] - 156s 17s/step - loss: 43.5077 - val_loss: 64.6603\n","Epoch 15/50\n","9/9 [==============================] - 155s 17s/step - loss: 41.1524 - val_loss: 51.2628\n","Epoch 16/50\n","9/9 [==============================] - 156s 17s/step - loss: 38.6925 - val_loss: 48.8157\n","Epoch 17/50\n","9/9 [==============================] - 156s 17s/step - loss: 37.4752 - val_loss: 46.4089\n","Epoch 18/50\n","9/9 [==============================] - 156s 17s/step - loss: 36.5534 - val_loss: 35.5527\n","Epoch 19/50\n","9/9 [==============================] - 157s 17s/step - loss: 33.0605 - val_loss: 37.0449\n","Epoch 20/50\n","9/9 [==============================] - 158s 18s/step - loss: 32.2998 - val_loss: 40.6312\n","Epoch 21/50\n","9/9 [==============================] - 158s 18s/step - loss: 30.7915 - val_loss: 40.4421\n","Epoch 22/50\n","9/9 [==============================] - 158s 18s/step - loss: 29.8828 - val_loss: 39.8966\n","Epoch 23/50\n","9/9 [==============================] - 157s 17s/step - loss: 28.5760 - val_loss: 29.6833\n","Epoch 24/50\n","9/9 [==============================] - 156s 17s/step - loss: 27.6991 - val_loss: 35.3412\n","Epoch 25/50\n","9/9 [==============================] - 155s 17s/step - loss: 26.8993 - val_loss: 29.5110\n","Epoch 26/50\n","9/9 [==============================] - 153s 17s/step - loss: 26.2863 - val_loss: 28.7179\n","Epoch 27/50\n","9/9 [==============================] - 152s 17s/step - loss: 25.6006 - val_loss: 28.6146\n","Epoch 28/50\n","9/9 [==============================] - 158s 18s/step - loss: 24.4920 - val_loss: 27.7165\n","Epoch 29/50\n","9/9 [==============================] - 156s 17s/step - loss: 24.6881 - val_loss: 31.0674\n","Epoch 30/50\n","9/9 [==============================] - 156s 17s/step - loss: 23.2257 - val_loss: 26.6293\n","Epoch 31/50\n","9/9 [==============================] - 156s 17s/step - loss: 22.6469 - val_loss: 31.0071\n","Epoch 32/50\n","9/9 [==============================] - 157s 17s/step - loss: 22.2558 - val_loss: 27.1349\n","Epoch 33/50\n","9/9 [==============================] - 156s 17s/step - loss: 21.9729 - val_loss: 24.0654\n","Epoch 34/50\n","9/9 [==============================] - 156s 17s/step - loss: 20.7181 - val_loss: 21.9174\n","Epoch 35/50\n","9/9 [==============================] - 157s 17s/step - loss: 21.2225 - val_loss: 25.0519\n","Epoch 36/50\n","9/9 [==============================] - 157s 17s/step - loss: 19.8449 - val_loss: 23.1204\n","Epoch 37/50\n","9/9 [==============================] - 157s 17s/step - loss: 19.9670 - val_loss: 26.1117\n","Epoch 38/50\n","9/9 [==============================] - 156s 17s/step - loss: 19.1790 - val_loss: 23.9264\n","Epoch 39/50\n","9/9 [==============================] - 157s 17s/step - loss: 18.7873 - val_loss: 21.1393\n","Epoch 40/50\n","9/9 [==============================] - 157s 17s/step - loss: 18.5140 - val_loss: 20.6781\n","Epoch 41/50\n","9/9 [==============================] - 156s 17s/step - loss: 18.8992 - val_loss: 21.3522\n","Epoch 42/50\n","9/9 [==============================] - 157s 17s/step - loss: 18.0335 - val_loss: 22.9074\n","Epoch 43/50\n","9/9 [==============================] - 156s 17s/step - loss: 18.0252 - val_loss: 19.3425\n","Epoch 44/50\n","9/9 [==============================] - 155s 17s/step - loss: 17.6385 - val_loss: 20.3001\n","Epoch 45/50\n","9/9 [==============================] - 155s 17s/step - loss: 17.2212 - val_loss: 20.0637\n","Epoch 46/50\n","9/9 [==============================] - 156s 17s/step - loss: 16.8378 - val_loss: 21.5797\n","Epoch 47/50\n","9/9 [==============================] - 156s 17s/step - loss: 16.7319 - val_loss: 21.5480\n","Epoch 48/50\n","9/9 [==============================] - 155s 17s/step - loss: 16.7844 - val_loss: 20.6387\n","Epoch 49/50\n","9/9 [==============================] - 155s 17s/step - loss: 16.4675 - val_loss: 18.5495\n","Epoch 50/50\n","9/9 [==============================] - 156s 17s/step - loss: 16.4288 - val_loss: 20.3172\n","Unfreeze all of the layers.\n","Train on 72 samples, val on 7 samples, with batch size 8.\n","Epoch 51/100\n","9/9 [==============================] - 431s 48s/step - loss: 12.1485 - val_loss: 12.1782\n","Epoch 52/100\n","9/9 [==============================] - 415s 46s/step - loss: 10.5480 - val_loss: 11.1788\n","Epoch 53/100\n","9/9 [==============================] - 411s 46s/step - loss: 10.2912 - val_loss: 10.5627\n","Epoch 54/100\n","9/9 [==============================] - 407s 45s/step - loss: 10.1401 - val_loss: 10.2597\n","Epoch 55/100\n","9/9 [==============================] - 399s 44s/step - loss: 10.0259 - val_loss: 10.1003\n","Epoch 56/100\n","9/9 [==============================] - 408s 45s/step - loss: 9.9532 - val_loss: 10.0176\n","Epoch 57/100\n","9/9 [==============================] - 411s 46s/step - loss: 9.8766 - val_loss: 9.9059\n","Epoch 58/100\n","9/9 [==============================] - 409s 45s/step - loss: 9.8166 - val_loss: 9.8401\n","Epoch 59/100\n","9/9 [==============================] - 405s 45s/step - loss: 9.7591 - val_loss: 9.7823\n","Epoch 60/100\n","9/9 [==============================] - 407s 45s/step - loss: 9.7044 - val_loss: 9.7170\n","Epoch 61/100\n","9/9 [==============================] - 409s 45s/step - loss: 9.6544 - val_loss: 9.6612\n","Epoch 62/100\n","9/9 [==============================] - 409s 45s/step - loss: 9.6091 - val_loss: 9.6210\n","Epoch 63/100\n","9/9 [==============================] - 409s 45s/step - loss: 9.5682 - val_loss: 9.5715\n","Epoch 64/100\n","9/9 [==============================] - 413s 46s/step - loss: 9.5233 - val_loss: 9.5222\n","Epoch 65/100\n","9/9 [==============================] - 413s 46s/step - loss: 9.4784 - val_loss: 9.4756\n","Epoch 66/100\n","9/9 [==============================] - 412s 46s/step - loss: 9.4318 - val_loss: 9.4312\n","Epoch 67/100\n","9/9 [==============================] - 412s 46s/step - loss: 9.3926 - val_loss: 9.3931\n","Epoch 68/100\n","9/9 [==============================] - 411s 46s/step - loss: 9.3532 - val_loss: 9.3519\n","Epoch 69/100\n","9/9 [==============================] - 411s 46s/step - loss: 9.3087 - val_loss: 9.3107\n","Epoch 70/100\n","8/9 [=========================>....] - ETA: 43s - loss: 9.2700 "],"name":"stdout"}]}]}